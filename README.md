# ğŸ•¸ï¸ Web Scraping & Data Mining (E-commerce)

> **Tecnologias:** Python, Selenium, BeautifulSoup, Pandas | **Status:** ConcluÃ­do
> **Foco:** ETL, Tratamento de Erros e ExtraÃ§Ã£o em Larga Escala.

### O CenÃ¡rio
A necessidade de monitorar preÃ§os e catÃ¡logo de produtos de concorrentes ou fornecedores exige automaÃ§Ã£o. Fazer isso manualmente para milhares de SKUs Ã© inviÃ¡vel.

### ğŸ’¡ A SoluÃ§Ã£o
Desenvolvi um **Crawler (RobÃ´ de Varredura)** robusto que navega autonomamente por todas as categorias de um e-commerce alvo.
Diferente de scripts simples, este robÃ´ possui **Auto-Healing**: se a conexÃ£o falhar ou o site bloquear, ele reinicia o navegador e retoma a extraÃ§Ã£o sem perder os dados jÃ¡ coletados.

### âš™ï¸ Fluxo de ExecuÃ§Ã£o

```mermaid
graph TD
    A[ğŸš€ Iniciar Driver] --> B[ğŸ—ºï¸ Mapear Categorias]
    B --> C{Loop por Categoria}
    C -->|Acessar URL| D[ğŸ“„ Extrair Produtos PÃ¡g. 1]
    D --> E{Tem PaginaÃ§Ã£o?}
    E -- Sim --> F[ğŸ”„ Loop: PrÃ³ximas PÃ¡ginas]
    E -- NÃ£o --> G[ğŸ’¾ Armazenar em MemÃ³ria]
    F --> G
    G --> H{Erro de ConexÃ£o?}
    H -- Sim --> I[ğŸ› ï¸ Reiniciar Driver e Tentar Novamente]
    I --> C
    H -- NÃ£o --> J[ğŸ“Š Exportar Excel Final]
